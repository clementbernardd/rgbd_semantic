{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"gcn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YY16x3cNoTIu"},"source":["# Git Importations "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pdm2F2AmmYjQ","executionInfo":{"status":"ok","timestamp":1606235608842,"user_tz":-60,"elapsed":789,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}},"outputId":"4a8b2ace-3147-48b0-e1cc-971678f31acf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vh5QZanwpN0E","executionInfo":{"status":"ok","timestamp":1606235610105,"user_tz":-60,"elapsed":609,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}},"outputId":"2213cb5d-fc9a-4642-9cab-d684aa987487"},"source":["%cd drive/My Drive/INF8801A/rgbd_semantic/code"],"execution_count":97,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive/INF8801A/rgbd_semantic/code'\n","/content/drive/My Drive/INF8801A/rgbd_semantic/code\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D8SZ4fEWec5v"},"source":["# Importations"]},{"cell_type":"code","metadata":{"id":"4opA6QwJec53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606235611250,"user_tz":-60,"elapsed":643,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}},"outputId":"b29e2d39-4e15-4737-967b-b3c9555cc5b4"},"source":["from importations import * \n","from utils import * \n","from cbr import * \n","from cbr_t import * \n","from encoder import * \n","from decoder import * \n","from fusenet import *\n","from evaluation import * \n","from gcn_encoder import * \n","from gcn_decoder import * \n","from gcn_module import * \n","%load_ext tensorboard\n","\n","# Device \n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":98,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OPiMGFQ7ozrm"},"source":["# Load the dataset"]},{"cell_type":"code","metadata":{"id":"mlBxSWxGW26d","executionInfo":{"status":"ok","timestamp":1606235618925,"user_tz":-60,"elapsed":6610,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["train = load_obj('train')\n","val = load_obj('validation')\n","test = load_obj('test')"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"9eLJihnSz-1O","executionInfo":{"status":"ok","timestamp":1606235622300,"user_tz":-60,"elapsed":9533,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}},"outputId":"3da44230-0e0e-4467-b8e4-e226e769a811"},"source":["''' Dataset  '''\n","X_train , y_train = get_train_val_test(train, is_torch = True  ) \n","X_val, y_val = get_train_val_test(val, is_torch = True )\n","X_test, y_test = get_train_val_test(test, is_torch = True)\n","\n","''' One hot labels '''\n","# Training set\n","# y_train_hot = load_obj('train_hot_labels')\n","# Validation set \n","# y_val_hot = load_obj('val_hot_labels')\n","# Testing set \n","# y_test_hot = load_obj('test_hot_labels')\n","\n","\n"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' One hot labels '"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"MEr1cPUo5LKN","executionInfo":{"status":"ok","timestamp":1606235622302,"user_tz":-60,"elapsed":9193,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["del train, val "],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjBqlGLXec6S","executionInfo":{"status":"ok","timestamp":1606235622305,"user_tz":-60,"elapsed":8939,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["# Global Variables \n","\n","IMG_SIZE = np.array(X_train[0][0,:].shape)\n","DEPTH_SIZE = np.array(X_train[1][0,:].shape)\n","LABEL_SIZE = np.array(y_train[0,:].shape)\n"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fAsKAqbec6W","executionInfo":{"status":"ok","timestamp":1606235622307,"user_tz":-60,"elapsed":8656,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}},"outputId":"bd6ef69a-af23-4b29-bd37-c9b1841d0117"},"source":["print(IMG_SIZE)\n","print(DEPTH_SIZE)\n","print(LABEL_SIZE)"],"execution_count":103,"outputs":[{"output_type":"stream","text":["[  3 240 320]\n","[  1 240 320]\n","[240 320]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7nzjXx9so0vr"},"source":["# GCN\n"]},{"cell_type":"markdown","metadata":{"id":"aoADuIWj86Oi"},"source":["![Image of Yaktocat](https://raw.githubusercontent.com/clementbernardd/rgbd_semantic/main/images/gcn.png)\n","\n"]},{"cell_type":"code","metadata":{"id":"k9XvK3rJHNPJ","executionInfo":{"status":"ok","timestamp":1606236813984,"user_tz":-60,"elapsed":849,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["class GCN(nn.Module) : \n","  ''' GCN network implementation '''\n","  def __init__(self,N , name = 'gcn') : \n","    ''' \n","      Inputs : \n","        - N : The number of classes in the dataset\n","        - name : The name of the model for the saving processing\n","    '''\n","    super(GCN , self).__init__()\n","    self.N = N\n","    self.name = name\n","    self.checkpoint_file = os.path.join('../model/' , name )\n","\n","    self.gcn_encoder = GCN_ENCODER(3,1)\n","    self.gcn_decoder = GCN_DECODER(512, N)\n","\n","  def forward(self, x):\n","    # Encode the data\n","    x, unpool, pool, gcns = self.gcn_encoder(x)\n","    # Add the unpool indexes\n","    self.gcn_decoder.unpool_indexes = unpool\n","    self.gcn_decoder.pool = pool\n","    self.gcn_decoder.gcns = gcns\n","    # Decode the data\n","    x = self.gcn_decoder(x)\n","    # Argmax for the prediction\n","    x = torch.nn.functional.log_softmax(x, dim = 1 )\n","\n","    return x.type(torch.float64)\n","\n","  def save_checkpoint(self) :\n","      print('--- Save model checkpoint ---')\n","      torch.save(self.state_dict(), self.checkpoint_file)\n","\n","  def load_checkpoint(self) :\n","      print('--- Loading model checkpoint ---')\n","      if torch.cuda.is_available() :\n","\n","          self.load_state_dict(torch.load(self.checkpoint_file))\n","\n","      else :\n","          self.load_state_dict(torch.load(self.checkpoint_file,map_location=torch.device('cpu')))\n","\n","\n","  def load_vgg(self,dict_conversion_vgg_name , is_trainable = False ) :\n","    ''' Load the parameters of VGG 16 network '''\n","    # Load the VGG-16 Net network\n","    vgg16 = models.vgg16_bn( pretrained=True)\n","    # Get the parameters\n","    vgg_16_parameters = dict(vgg16.features.state_dict())\n","    # Get the model parameters\n","    params = dict(self.state_dict())\n","    # Loop over the dictionnary that maps the VGG16-net and our model\n","    for key in dict_conversion_vgg_name :\n","      # Set our parameters to be the one of the VGG16-net\n","      params[key] = vgg_16_parameters[dict_conversion_vgg_name[key]]\n","    # Update the paramters\n","    self.load_state_dict(params)\n","    # If not_trainable\n","    if not is_trainable :\n","      for param in self.named_parameters():\n","        # Make the VGG16-net parameters not trainable\n","        if param[0] in dict_conversion_vgg_name :\n","          param[1].requires_grad = False\n","  "],"execution_count":132,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJmVNsTbaO5i","executionInfo":{"status":"ok","timestamp":1606215442375,"user_tz":-60,"elapsed":665,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["def launch_tensorboard(name, erase = False) : \n","    ''' Launch the tensorboard for the given name directory '''\n","    if erase : \n","        %rm -r {name}\n","    %tensorboard --logdir {name}"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IkhJVx9z-1P","executionInfo":{"status":"ok","timestamp":1606215444403,"user_tz":-60,"elapsed":1096,"user":{"displayName":"Clément BERNARD","photoUrl":"","userId":"11436881925998552394"}}},"source":["class Train(object) : \n","    ''' Object that deals the training process '''\n","    def __init__(self, X_train, y_train , y_train_hot,BATCH_SIZE, print_iter, criterion, \\\n","                 optimizer, learning_rate, model,N, name, X_val = None, y_val = None  ) :\n","        ''' \n","        Inputs : \n","            - X_train : The training inputs \n","            - y_train : The training labels \n","            - y_train_hot : The hot-encoded training labels \n","            - BATCH_SIZE : The size of the mini-batch used for the training process\n","            - print_iter : The number of time we plot the loss/scores during the training \n","            - criterion : The criterion used \n","            - optimizer : The optimizer used (like : optim.Adam)\n","            - learning_rate : The learning rate for the optimizer\n","            - model : FuseNet or GCN \n","            - N : the number of classes\n","            - name : The name where will be stored the model parameters \n","        '''\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.y_train_hot = y_train_hot\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.print_iter = print_iter\n","        self.criterion = criterion\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.model = model(N+1, name).to(self.device)\n","        self.learning_rate = learning_rate\n","        self.optimizer = optimizer(self.model.parameters(), lr = learning_rate)\n","        self.name = name \n","        self.N = N \n","        self.X_val = X_val \n","        self.y_val = y_val \n","\n","        \n","        self.evaluation = Evaluation()\n","        self.chkpt_dir = '../tmp/'+ self.name\n","\n","        self.scores_train = {}\n","        self.scores_val = {}\n","        self.loss_train = {}\n","                \n","    \n","    def predict(self, X ) : \n","        ''' Predict the output for X as inputs '''\n","        # Check if the size of the batch is below the BATCH_SIZE \n","        if X[0].shape[0] < self.BATCH_SIZE : \n","            \n","            predictions = convert_hot_to_squeeze_all(self.model(X).cpu())\n","            \n","        else : \n","            # Split the data into mini_batch to compute the prediction \n","            current_batch = 0\n","            # Number of images \n","            n = X[0].shape[0]\n","            # Indexes to map the images\n","            idxs = np.arange(n)\n","            # Predictions to return\n","            predictions = np.zeros((n, X[0].shape[2], X[0].shape[3]))\n","            self.model.eval()\n","            # Loop over the number of mini-batches\n","            while current_batch < n  :\n","                # Get the current indexes\n","                index = idxs[current_batch : min(n, current_batch+self.BATCH_SIZE)] \n","                # Get the current X \n","                current_x = [X[0][index,:].to(self.device) , X[1][index,:].to(self.device)]\n","                # Without gradient \n","                with torch.no_grad() :\n","                    # Compute the prediction\n","                    prediction = self.model(current_x).reshape(-1,self.N+1, 240,320)\n","                    # Increase the current batch\n","                    current_batch+= self.BATCH_SIZE\n","                    # Take the argmax for the prediction\n","                    prediction = convert_hot_to_squeeze_all(prediction.cpu())\n","                    # Add it to the output \n","                    predictions[index, :] = prediction\n","\n","            self.model.train()\n","        return np.array(predictions)\n","        \n","        \n","    def score(self, X, y) : \n","        ''' Return the score for the inputs X and the output y '''\n","        prediction = self.predict(X)\n","        scores = self.evaluation.get_scores(prediction,y.cpu())\n","        return scores \n","        \n","            \n","        \n","    def train(self, n_epochs, to_load = False, to_save = True, epoch_start = 0 ) : \n","        ''' Train the models with the number of epochs '''\n","        \n","        if to_load : \n","            self.model.load_checkpoint()\n","            \n","        n = self.X_train[0].shape[0]\n","        # To store the loss \n","        writer = SummaryWriter(self.chkpt_dir)\n","\n","        \n","        for e in range(epoch_start, n_epochs) : \n","            current_loss = 0\n","            \n","            idxs = np.arange(n)\n","            # Shuffle for the mini-batch\n","            np.random.shuffle(idxs)\n","            # Initialise the counter of the mini_batch \n","            current_batch = 0\n","            while current_batch < n :  \n","                # Get the mini-batches\n","                batch_x , batch_y = get_batch(self.X_train, self.y_train, idxs ,\\\n","                                              current_batch, self.BATCH_SIZE)\n","                # Convert the labels into one hot vectors \n","                batch_x = [batch_x[0].to(self.device),batch_x[1].to(self.device)]\n","                # batch_y = torch.from_numpy(one_hot_encode(batch_y, N= self.N+1)).to(self.device)\n","                batch_y = batch_y.to(self.device)\n","                # Increase the current batch  \n","                current_batch+=self.BATCH_SIZE\n","                # Zero the parameters of the gradients \n","                self.optimizer.zero_grad()\n","                # Forward for the prediction\n","                batch_pred = self.model(batch_x)\n","                # Reshape the output \n","                batch_pred = batch_pred.reshape(-1, self.N+1, 240,320)\n","                # Reshape the target \n","                # batch_y = batch_y.reshape(-1, 240,320,  self.N+1).to(dtype=torch.long)\n","                # Compute the loss \n","                loss = self.criterion(batch_pred, torch.squeeze(batch_y).long())\n","                # Add it to store \n","                current_loss+=loss.detach().item()\n","                # Backward step \n","                loss.backward()\n","                self.optimizer.step()\n","                \n","            current_loss/=self.BATCH_SIZE\n","            self.loss_train[e] = current_loss\n","            writer.add_scalar(\"loss/\", current_loss, e )\n","\n","            if e % self.print_iter == 0 : \n","                scores = self.score(self.X_train , self.y_train)\n","                self.scores_train[e] = scores.copy()\n","              \n","                print('Epoch : {}  Loss : {:.2f}  Pixel acc : {:.2f} Mean acc : {:.2f} Mean IoU : {:.2f}'.format(e, current_loss,\\\n","                                                                                                 scores['Pixel_accuracy'],scores['Mean_accuracy'],\\\n","                                                                                                   scores['Mean_iou']))\n","                if self.X_val is not None : \n","                  scores_val = self.score(self.X_val , self.y_val)\n","                  print('Validation set : Pixel acc : {:.2f} Mean accuracy : {:.2f} Mean IoU : {}'.format(e,\\\n","                                                                                                 scores_val['Pixel_accuracy'],\\\n","                                                                                                 scores_val['Mean_accuracy'],\\\n","                                                                                                   scores_val['Mean_iou']))              \n","\n","                  writer.add_scalar(\"scores/pixel_acc_val\", scores_val['Pixel_accuracy'], e )\n","                  writer.add_scalar(\"scores/mean_acc_val\", scores_val['Mean_accuracy'], e )\n","                  writer.add_scalar(\"scores/mean_iou_val\", scores_val['Mean_iou'], e )\n","\n","                  self.scores_val[e] = scores_val.copy()\n","\n","                writer.add_scalar(\"scores/pixel_acc\", scores['Pixel_accuracy'], e )\n","                writer.add_scalar(\"scores/mean_acc\", scores['Mean_accuracy'], e )\n","                writer.add_scalar(\"scores/mean_iou\", scores['Mean_iou'], e )\n","                                 \n","\n","\n","\n","                self.model.save_checkpoint()\n","            \n","        writer.flush()\n","        writer.close()\n","\n","        "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJKH1BXnw65I"},"source":["## Training without VGG-16 Net transfer learning for the encoder"]},{"cell_type":"code","metadata":{"id":"oX6GI30tM9sx"},"source":["params_train_vgg_gcn = {\n","    'X_train' : X_train,\n","    'y_train' : y_train, \n","    'y_train_hot' : None, \n","    'BATCH_SIZE' : 16, \n","    'print_iter' : 50,\n","    'criterion' : nn.CrossEntropyLoss(),\n","    'optimizer' : optim.Adam,\n","    'learning_rate' : 1e-2,\n","    'model' : GCN,\n","    'N' : N,\n","    'name' : 'gcn',\n","    'X_val' : X_val,\n","    'y_val' : y_val\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1mvKdN9hM-uq"},"source":["train_gcn = Train(**params_train_vgg_gcn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kByn1ysLNQx2"},"source":["train_gcn.model.load_vgg(dict_conversion_vgg_name_gcn, is_trainable=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Am1XZvb2M-xL"},"source":["train_gcn.train(n_epochs = 300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMk6oN_jM-1J"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3lwaG8TM-3O"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wjMjGNFM-5J"},"source":[""],"execution_count":null,"outputs":[]}]}